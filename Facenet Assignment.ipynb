{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6411b320",
   "metadata": {},
   "source": [
    "## The Facenet Library\n",
    "* The case of face detection using Facenet library's models is an interesting case. We don't have to train anything or worry about models or hyperparameters. We simply generate embeddings.\n",
    "* Embeddings are generating using Facenet's CNN models that is for detedting fac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33537916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Initialize MTCNN and InceptionResnetV1\n",
    "mtcnn = MTCNN(image_size=160, margin=20)\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e2490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the dataset containing folders of individuals (for known faces)\n",
    "dataset_path = \"./faces/\"  # Replace with your dataset path\n",
    "\n",
    "# Threshold for similarity matching\n",
    "threshold = 0.6\n",
    "\n",
    "# Step 1: Generate embeddings for known faces\n",
    "\n",
    "known_embeddings = {}\n",
    "\n",
    "for person_name in os.listdir(dataset_path):\n",
    "   \n",
    "    person_folder = os.path.join(dataset_path, person_name)\n",
    "    \n",
    "    if os.path.isdir(person_folder):\n",
    "        for image_name in os.listdir(person_folder):\n",
    "            \n",
    "            image_path = os.path.join(person_folder, image_name)\n",
    "            try:\n",
    "                # Load image and process with MTCNN\n",
    "                \n",
    "                image = Image.open(image_path)\n",
    "                cropped_face = mtcnn(image)\n",
    "\n",
    "                if cropped_face is not None:\n",
    "                    # Generate 128D embeddings for the face\n",
    "                   \n",
    "                    embedding = model(cropped_face.unsqueeze(0))\n",
    "                    known_embeddings[person_name] = embedding.detach()\n",
    "                    break  # Only use one image per person\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d91626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found: Abdullah_Gul (Similarity: 0.90)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "import numpy as np\n",
    "def recognize_face(test_image_path):\n",
    "    try:\n",
    "        # Load test image and process with MTCNN\n",
    "        test_image = Image.open(test_image_path)\n",
    "       \n",
    "        cropped_face = mtcnn(test_image)\n",
    "        \n",
    "\n",
    "        if cropped_face is None:\n",
    "            \n",
    "            print(\"No face detected in the image.\")\n",
    "            return\n",
    "\n",
    "        # Generate embedding for the test image\n",
    "        test_embedding = np.array(model(cropped_face.unsqueeze(0)).detach()).flatten()\n",
    "       \n",
    "\n",
    "        # Compare with known embeddings\n",
    "        for person_name, known_embedding in known_embeddings.items():\n",
    "            \n",
    "            cosine_measure=cosine(test_embedding, np.array(known_embedding).flatten())\n",
    "           \n",
    "            similarity=1-cosine_measure\n",
    "            \n",
    "            if similarity > threshold:\n",
    "                print(f\"Match found: {person_name} (Similarity: {similarity:.2f})\")\n",
    "                return\n",
    "\n",
    "        print(\"No match found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing test image: {e}\")\n",
    "\n",
    "# Example usage\n",
    "\n",
    "test_image_path = r\"C:\\Users\\PMLS\\OneDrive - Higher Education Commission\\Documents\\University Work\\Sixth Semester\\Machine Learning\\Assignments\\Facenet assignment\\faces\\Abdullah_Gul\\Abdullah_Gul_0014.jpg\"  # Replace with the test image path\n",
    "recognize_face(test_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fddf5d",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "* The results are comprehensibly correct. \n",
    "* Although we have generating embeddings for each person based on a single image which could result in bad representation issue and declined accuracy but the model was checked with 2 random images of 2 people and the results were accurate and the model was able to correctly identify the face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c58d47b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feasibility",
   "language": "python",
   "name": "feasibility"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
